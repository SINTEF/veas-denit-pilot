{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=os.getcwd(),\n",
    "    indicator=[\".git\", \"pyproject.toml\"],\n",
    "    pythonpath=True,\n",
    "    dotenv=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "\n",
    "import src.utils.plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inspect Iterative Experiment Results\n",
    "This notebook aids in inspecting the results of the iterative data chunks experiments, and in collecting the necessary information for the paper: gathering the figures and outputting latex table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def search_mlflow(\n",
    "    search_experiment_name,\n",
    "    mlflow_tracking_uri=None,\n",
    "    mlflow_file_path=None,\n",
    "):\n",
    "    tags_model_to_name = dict(\n",
    "        XGB=\"XGBoost\",\n",
    "        TCN=\"TCN\",\n",
    "        RNN=\"LSTM\",\n",
    "        Regression=\"ElasticNet\",\n",
    "        NaiveSeasonal=\"BaselineSeasonal\",\n",
    "        TCNNoTarget=\"TCN\",\n",
    "        RNNNoTarget=\"LSTM\",\n",
    "    )\n",
    "    if isinstance(search_experiment_name, str):\n",
    "        search_experiment_name = [search_experiment_name]\n",
    "\n",
    "    if mlflow_file_path is None:\n",
    "        mlflow_file_path = os.path.join(root, \"logs\", \"mlflow\", \"mlruns\")\n",
    "\n",
    "    if mlflow_tracking_uri is None:\n",
    "        assert mlflow_file_path is not None\n",
    "        mlflow_tracking_uri = f\"file:///{mlflow_file_path}\"\n",
    "\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    df = mlflow.search_runs(experiment_names=search_experiment_name)\n",
    "    if df.empty:\n",
    "        raise ValueError(\n",
    "            f\"Did not find experiment with name: {search_experiment_name} on tracking uri: {mlflow_tracking_uri}\"\n",
    "        )\n",
    "\n",
    "    # df[\"model_name\"] = df.apply(get_model_name, axis=1)\n",
    "    df[\"tags.model\"] = df[\"tags.model\"].apply(\n",
    "        lambda x: tags_model_to_name.get(x.replace(\"Model\", \"\"), x.replace(\"Model\", \"\"))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# n_missing: for nowcasting, the combination with all inputs disabled is not valid and missing from some datasets\n",
    "def check_completeness(df, input_names, n_missing=0):\n",
    "    df_sub = df[input_names]\n",
    "\n",
    "    # Convert each row to a tuple\n",
    "    combinations = df_sub.apply(tuple, axis=1)\n",
    "\n",
    "    n_combinations = 2 ** len(input_names) - n_missing\n",
    "\n",
    "    # Check if there are n_combinations unique combinations\n",
    "    unique_combinations = combinations.nunique()\n",
    "    total_combinations = len(combinations)\n",
    "\n",
    "    if (\n",
    "        abs(unique_combinations - n_combinations) <= n_missing\n",
    "        and abs(total_combinations - n_combinations) <= n_missing\n",
    "    ):\n",
    "        print(f\"All {n_combinations} unique combinations are present and there are no duplicates.\")\n",
    "    else:\n",
    "        print(f\"Expected number of combinations: {n_combinations}\")\n",
    "        print(f\"Number of unique combinations: {unique_combinations}\")\n",
    "        print(f\"Total number of combinations: {total_combinations}\")\n",
    "        if unique_combinations < n_combinations:\n",
    "            print(\"Some combinations are missing.\")\n",
    "        if total_combinations > n_combinations:\n",
    "            print(\"There are duplicates in the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean metric score by input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = \"veas_pilot\"\n",
    "model = \"rnn\"\n",
    "metric_name = \"test_mse\"\n",
    "task = \"nowcast\"\n",
    "fig_folder = os.path.join(root, \"figures\", dataset, \"input_analysis\", task)\n",
    "\n",
    "\n",
    "metric_column = f\"metrics.{metric_name}\"\n",
    "tags_model_to_name = dict(\n",
    "    XGBModel=\"XGBoost\", TCNModel=\"TCN\", RNNModel=\"LSTM\", RegressionModel=\"ElasticNet\"\n",
    ")\n",
    "\n",
    "search_experiment_name = {\n",
    "    \"xgboost\": f\"{dataset}-inputs_test-{task}-{dataset}_{model}_{task}\",\n",
    "    \"tcn\": f\"{dataset}-inputs_test-{task}-{dataset}_{model}_{task}\",\n",
    "    \"elastic_net\": f\"{dataset}-inputs_test-{task}-{dataset}_{model}_{task}\",\n",
    "    \"rnn\": f\"hopt-{dataset}-inputs_test-{task}-{dataset}_{model}_{task}\",\n",
    "}\n",
    "\n",
    "df = search_mlflow(search_experiment_name[model])\n",
    "\n",
    "input_data_method = (\n",
    "    \"use_inputs\" if search_experiment_name[model].startswith(\"hopt\") else \"data_variables\"\n",
    ")\n",
    "\n",
    "if input_data_method == \"use_inputs\":\n",
    "    input_columns = [col for col in df.columns if \"use_inputs\" in col]\n",
    "    input_names_clean = {col: col.split(\"/\")[-1] for col in input_columns}\n",
    "\n",
    "    for col in input_columns:\n",
    "        df[col] = df[col] == \"True\"\n",
    "elif input_data_method == \"data_variables\":\n",
    "    # in this case use_input is not a dictionary with True False for each input. Therefore we create these columns\n",
    "    # on the format that the rest of the notebook expects\n",
    "    all_inputs = set()\n",
    "    if model == \"tcn\":\n",
    "        data_variables_column = \"params.datamodule/data_variables/past_covariates\"\n",
    "    else:\n",
    "        data_variables_column = \"params.datamodule/data_variables/future_covariates\"\n",
    "\n",
    "    for input_combination in df[data_variables_column].dropna().unique():\n",
    "        all_inputs.update(input_combination.strip(\"[]\").replace(\"'\", \"\").split(\", \"))\n",
    "    input_columns = [f\"params.use_inputs/{input_name}\" for input_name in all_inputs]\n",
    "    input_names_clean = {\n",
    "        f\"params.use_inputs/{input_name}\": input_name for input_name in all_inputs\n",
    "    }\n",
    "\n",
    "    for input_name in input_names_clean.values():\n",
    "        df[f\"params.use_inputs/{input_name}\"] = df[data_variables_column].apply(\n",
    "            lambda x: input_name in x if pd.notnull(x) else False\n",
    "        )\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "plot_input_names = src.utils.plotting.get_covariate_plot_names()\n",
    "input_names_clean = {col: plot_input_names[col_v] for col, col_v in input_names_clean.items()}\n",
    "df = df.rename(columns=input_names_clean)\n",
    "input_columns = list(input_names_clean.values())\n",
    "\n",
    "df = df.drop_duplicates(subset=input_columns)\n",
    "check_completeness(df, input_columns, n_missing=1 if task == \"nowcast\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_span = \"double\"\n",
    "height = 8\n",
    "mean_relative = False\n",
    "src.utils.plotting.set_matplotlib_attributes(font_size=8)\n",
    "\n",
    "plot_data = []\n",
    "mean_all = df[metric_column].mean()\n",
    "\n",
    "# Compute mean metrics.val_mse for each input condition (True and False)\n",
    "for col in input_columns:\n",
    "    true_mean = df[df[col]][metric_column].mean()\n",
    "    false_mean = df[~df[col]][metric_column].mean()\n",
    "    if mean_relative:\n",
    "        true_mean -= mean_all\n",
    "        false_mean -= mean_all\n",
    "    plot_data.append({\"input\": col, \"used\": \"True\", \"mean_val_mse\": true_mean})\n",
    "    plot_data.append({\"input\": col, \"used\": \"False\", \"mean_val_mse\": false_mean})\n",
    "\n",
    "# Create a DataFrame from the plot data\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "sns.barplot(\n",
    "    data=plot_df, x=\"input\", y=\"mean_val_mse\", hue=\"used\", order=plot_df[\"input\"].sort_values()\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "plt.xlabel(\"Covariate\")\n",
    "\n",
    "if mean_relative:\n",
    "    plt.title(f'Change in MSE by Covariate Usage for {df[\"tags.model\"][0]} {task.capitalize()}')\n",
    "    plt.ylabel(\"$\\Delta$ Mean MSE\")\n",
    "else:\n",
    "    plt.title(f'MSE by Input Covariate for {df[\"tags.model\"][0]} {task.capitalize()}')\n",
    "    plt.ylabel(\"Mean MSE\")\n",
    "\n",
    "if model == \"elastic_net\":\n",
    "    plt.legend(title=\"Covariate Used\")\n",
    "else:\n",
    "    plt.legend([])\n",
    "\n",
    "plt.tight_layout()\n",
    "if mean_relative:\n",
    "    fig_path = os.path.join(fig_folder, f\"relative_mean_mse_by_input_usage_{model}\")\n",
    "else:\n",
    "    fig_path = os.path.join(fig_folder, f\"mean_mse_by_input_usage_{model}\")\n",
    "fig = plt.gcf()\n",
    "src.utils.plotting.set_figure_size(fig, column_span, height=height)\n",
    "src.utils.plotting.save_figure(fig, fig_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_span = \"double\"\n",
    "top_x = 50  # Number of top models to consider\n",
    "height = 8\n",
    "\n",
    "# Sort DataFrame and select top models based on the metric\n",
    "top_models = df.nsmallest(top_x, f\"metrics.{metric_name}\")\n",
    "\n",
    "# Calculate the usage percentage of each input among the top models\n",
    "input_usage_counts = top_models[input_columns].sum()\n",
    "input_usage_percentages = (input_usage_counts / top_x) * 100\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_data = []\n",
    "for input_col, percentage in input_usage_percentages.items():\n",
    "    plot_data.append(\n",
    "        {\n",
    "            \"input\": input_col.replace(\"params.use_inputs/\", \"\"),  # Clean input names\n",
    "            \"percentage\": percentage,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert to DataFrame\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(\n",
    "    data=plot_df, x=\"input\", y=\"percentage\", color=\"skyblue\", order=plot_df[\"input\"].sort_values()\n",
    ")\n",
    "plt.title(\n",
    "    f'Percentage of Top {top_x} Models Using Each Covariate for {df[\"tags.model\"][0]} {task.capitalize()}'\n",
    ")\n",
    "plt.xlabel(\"Covariate\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "# plt.grid(axis=\"y\")\n",
    "plt.yticks(range(0, 120, 20))\n",
    "plt.xticks(rotation=30)  # Rotate labels for better readability\n",
    "\n",
    "fig = plt.gcf()\n",
    "src.utils.plotting.set_figure_size(fig, column_span=column_span, height=height)\n",
    "src.utils.plotting.save_figure(fig, os.path.join(fig_folder, f\"top_{top_x}_models_{model}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible combinations of input conditions\n",
    "input_conditions = list(itertools.product([False, True], repeat=len(input_columns)))\n",
    "\n",
    "# Create a DataFrame to hold combination data\n",
    "combinations = []\n",
    "for condition in input_conditions:\n",
    "    mask = (df[input_columns] == condition).all(axis=1)\n",
    "    mean_metric = df.loc[mask, metric_column].mean()\n",
    "    combinations.append(list(condition) + [mean_metric])\n",
    "\n",
    "# Columns for the new DataFrame\n",
    "columns = input_columns + [\"mean_val_mse\"]\n",
    "combination_df = pd.DataFrame(combinations, columns=columns)\n",
    "\n",
    "# Melt DataFrame for heatmap usage\n",
    "heatmap_data = combination_df.melt(id_vars=\"mean_val_mse\", var_name=\"input\", value_name=\"used\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "heatmap_data = heatmap_data.pivot_table(index=\"input\", columns=\"used\", values=\"mean_val_mse\")\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"viridis\")\n",
    "plt.title(\"Heatmap of Mean Val MSE Across Input Combinations\")\n",
    "plt.xlabel(\"Input Used\")\n",
    "plt.ylabel(\"Input Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df, input_columns, and input_names_clean are defined\n",
    "n_inputs = len(input_columns)\n",
    "\n",
    "fig, axs = plt.subplots(n_inputs - 1, n_inputs - 1, figsize=(20, 20))  # Adjusted size for clarity\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.6)  # Adjust space between plots\n",
    "\n",
    "for i in range(n_inputs):\n",
    "    for j in range(i + 1, n_inputs):\n",
    "        ax = axs[i, j - 1]\n",
    "        interaction_plot(\n",
    "            df[input_columns[i]].astype(int),\n",
    "            df[input_columns[j]].astype(int),\n",
    "            df[metric_column],\n",
    "            ax=ax,\n",
    "            colors=[\"red\", \"blue\"],\n",
    "            markers=[\"D\", \"o\"],\n",
    "            ms=10,\n",
    "        )\n",
    "        ax.set_title(\n",
    "            f\"{input_names_clean[input_columns[i]]} x {input_names_clean[input_columns[j]]}\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "        ax.legend(title=\"Condition\", title_fontsize=\"8\", fontsize=\"7\", loc=\"upper right\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(input_names_clean[input_columns[i]])\n",
    "        # Explicitly set axis labels and ticks visibility\n",
    "        ax.xaxis.set_tick_params(labelbottom=True)\n",
    "        ax.yaxis.set_tick_params(labelleft=True)\n",
    "\n",
    "# Hide plots for combinations that don't exist\n",
    "for i in range(n_inputs - 1):\n",
    "    for j in range(i + 1, n_inputs):\n",
    "        axs[j - 1, i].axis(\"off\")  # Hides the lower triangle and non-existing plots correctly\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to fit the plot and labels better\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "X = df[input_columns].astype(int)\n",
    "y = df[metric_column]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# PCA Transformation\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=\"viridis\")\n",
    "plt.colorbar(scatter, label=\"Val MSE\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA of Input Combinations Colored by Val MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "X = df[input_columns].astype(int)\n",
    "y = df[metric_column]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Model with interaction terms\n",
    "X_interaction = sm.tools.add_constant(X)\n",
    "regression_model = sm.OLS(y, X_interaction)\n",
    "results = regression_model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "# Remove constant coefficient\n",
    "results_params = results.params[1:]\n",
    "\n",
    "# Plotting the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(results_params)), results_params)\n",
    "plt.xlabel(\"Coefficients Index\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.title(f\"Impact of Inputs on {metric_name}\")\n",
    "plt.xticks(\n",
    "    ticks=range(len(results_params)),\n",
    "    labels=[input_names_clean[param] for param in results_params.index],\n",
    "    rotation=30,\n",
    ")\n",
    "src.utils.plotting.save_figure(\n",
    "    plt.gcf(), os.path.join(fig_folder, f\"input_impact_regression_{model}\")\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
